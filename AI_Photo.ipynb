{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000214AF324C18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000214AF10C048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "#!pip install mtcnn\n",
    "\n",
    "# import the necessary packages\n",
    "from pyimagesearch.blur_detector import detect_blur_fft\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import mtcnn\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import PySimpleGUI as sg\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################## BLUR DETECTION #############################\n",
    "\n",
    "test_image_link = r'1_Test_Images_Blur_Emotions'\n",
    "\n",
    "\n",
    "# Blur Detection\n",
    "def BlurDetection(test_image_link):\n",
    "\n",
    "    # set the blur/clear threshold\n",
    "    threshold = 10\n",
    "\n",
    "    int = 0    \n",
    "    for imagePath in paths.list_images(test_image_link) :\n",
    "            testimage = plt.imread(imagePath)\n",
    "            orig = cv2.imread(imagePath)\n",
    "            orig = imutils.resize(orig, width=500)\n",
    "            gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n",
    "            # apply our blur detector using the FFT\n",
    "            (mean, blurry) = detect_blur_fft(gray, size=60,thresh=threshold, vis=-1 > 0)   \n",
    "        \n",
    "            int = int + 1\n",
    "\n",
    "            if blurry == True :\n",
    "                    plt.imsave('1a_Blur_Images/' + str(int) + '.png', testimage , format='png')\n",
    "            #        os.remove(os.path.join(folder_path, images))\n",
    "            else :\n",
    "                    plt.imsave('1b_No_Blur/' + str(int) + '.png', testimage , format='png')\n",
    "\n",
    "\n",
    "                    \n",
    "################################## EMOTIONS #############################\n",
    "                    \n",
    "# Face Detection and Emotion Classification\n",
    "\n",
    "def FaceAndEmotion(test_image_link):\n",
    "\n",
    "    detector = mtcnn.MTCNN()\n",
    "\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    model.load_weights('model_epoch_50_lr0_0001.h5')\n",
    "    \n",
    "\n",
    "    # prevents openCL usage and unnecessary logging messages\n",
    "    cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "    # dictionary which assigns each label an emotion (alphabetical order)\n",
    "    emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "\n",
    "    int = 0    \n",
    "    for imagePath in paths.list_images(test_image_link) :\n",
    "            pixels = plt.imread(imagePath)\n",
    "        \n",
    "            faces = detector.detect_faces(pixels)\n",
    "            int = int + 1\n",
    "            if not faces:\n",
    "                    plt.imsave('2b_Not_Face/' + str(int) + '.png', pixels , format='png')\n",
    "                \n",
    "            else :\n",
    "                \n",
    "                    #draw face\n",
    "                    list = []\n",
    "                    #plt.imshow(pixels)\n",
    "                    #ax = plt.gca()\n",
    "                    for i in faces :\n",
    "                        x, y, width, height = i['box']\n",
    "                        list.append(i['box'])\n",
    "                        rect = plt.Rectangle((x,y), width, height, fill=False, color='red')\n",
    "                        #ax.add_patch(rect)\n",
    "                    #plt.axis('off')\n",
    "                    #plt.savefig(str(int) + '.png', bbox_inches='tight',pad_inches=0)\n",
    "                    #print(faces)\n",
    "                \n",
    "                    #print(list)\n",
    "                    list = [[0 if x < 0 else x for x in y] for y in list]\n",
    "                    #print(list)\n",
    "                    img = cv2.imread(imagePath)\n",
    "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                    for (x,y,w,h) in list:\n",
    "                            img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                            roi_gray = gray[y:y+h, x:x+w]\n",
    "                            roi_color = img[y:y+h, x:x+w]\n",
    "                            cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "                            prediction = model.predict(cropped_img)\n",
    "                            maxindex = (np.argmax(prediction))\n",
    "                            #maxindex = (np.predictions)\n",
    "                            #cv2.putText(img, emotion_dict[maxindex],  (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                            #cv2.imshow('img',img)\n",
    "                        \n",
    "                            if maxindex == 0 : \n",
    "                                 plt.imsave('2_Emotions/angry/' + str(int) + '.png',pixels, format='png')                        \n",
    "                            if maxindex == 1 : \n",
    "                                 plt.imsave('2_Emotions/disgusted/' + str(int) + '.png',pixels, format='png')                        \n",
    "                            if maxindex == 2 : \n",
    "                                 plt.imsave('2_Emotions/fearful/' + str(int) + '.png',pixels, format='png')                        \n",
    "                            if maxindex == 3 : \n",
    "                                 plt.imsave('2_Emotions/happy/' + str(int) + '.png',pixels, format='png')\n",
    "                            if maxindex == 4 : \n",
    "                                 plt.imsave('2_Emotions/neutral/' + str(int) + '.png',pixels, format='png')                        \n",
    "                            if maxindex == 5 : \n",
    "                                 plt.imsave('2_Emotions/sad/' + str(int) + '.png',pixels, format='png')                        \n",
    "                            if maxindex == 6 : \n",
    "                                 plt.imsave('2_Emotions/surprised/' + str(int) + '.png',pixels, format='png')\n",
    "                        \n",
    "                            #cv2.waitKey(0)\n",
    "                            #cv2.destroyAllWindows()\n",
    "                \n",
    "                    plt.imsave('2a_Face/' + str(int) + '.png',pixels, format='png')   \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "################################## CLASSIFICATIONS #############################\n",
    "                    \n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "#tensorflow:Model was constructed with shape (None, 160, 160, 3) \n",
    "#for input KerasTensor(type_spec=TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name='input_2'), \n",
    "                                    #name='input_2', description=\"created by layer 'input_2'\"), \n",
    "#but it was called on an input with incompatible shape (None, 160).\n",
    "\n",
    "classification_test_images = r'3_Test_Images_Classification'\n",
    "\n",
    "# Classification\n",
    "def Classification(classification_test_images):\n",
    "    \n",
    "    model = load_model('MobileNetV2_8classes_model_v3.h5')\n",
    "    \n",
    "    # dictionary which assigns each label an emotion (alphabetical order)\n",
    "    class_dict = {0: \"animals\", 1: \"architecture\", 2: \"art_and_culture\", 3: \"food_and_drinks\",\n",
    "                  4: \"landscapes\", 5: \"racing\", 6: \"sports\", 7: \"travel_and_adventure\"}\n",
    "    \n",
    "    int = 0    \n",
    "    for imagePath in paths.list_images(classification_test_images) :\n",
    "            pixels = plt.imread(imagePath)\n",
    "            image = cv2.imread(imagePath)\n",
    "            #class_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            class_image = np.expand_dims(np.expand_dims(cv2.resize(image, (160,160)), -1), 0)\n",
    "            predictions = model.predict(class_image) #.flatten()\n",
    "            \n",
    "            maxindex = (np.argmax(predictions))\n",
    "            \n",
    "            #Retrieve a batch of images from the test set\n",
    "            \n",
    "            if maxindex == 0 : \n",
    "                  plt.imsave('3a_Classifications/animals/' + str(int)  + '.png', pixels, format='png')                     \n",
    "            if maxindex == 1 : \n",
    "                  plt.imsave('3a_Classifications/architecture/' + str(int) + '.png', pixels, format='png')                        \n",
    "            if maxindex == 2 : \n",
    "                  plt.imsave('3a_Classifications/art_and_culture/' + str(int) + '.png', pixels, format='png')                        \n",
    "            if maxindex == 3 : \n",
    "                  plt.imsave('3a_Classifications/food_and_drinks/' + str(int) + '.png', pixels, format='png')\n",
    "            if maxindex == 4 : \n",
    "                  plt.imsave('3a_Classifications/landscapes/' + str(int) + '.png', pixels, format='png')                        \n",
    "            if maxindex == 5 : \n",
    "                  plt.imsave('3a_Classifications/racing/' + str(int) + '.png', pixels, format='png')                        \n",
    "            if maxindex == 6 : \n",
    "                  plt.imsave('3a_Classifications/sports/' + str(int) + '.png', pixels, format='png')\n",
    "            if maxindex == 7 : \n",
    "                  plt.imsave('3a_Classifications/travel_and_adventure/' + str(int) + '.png', pixels, format='png')\n",
    "\n",
    "                             #cv2.waitKey(0)\n",
    "                             #cv2.destroyAllWindows()\n",
    "                \n",
    "    #plt.imsave('3a_Classifications/' + '.png', image, format='png') #\n",
    "\n",
    "#Classification(3a_Classifications)\n",
    "\n",
    "\n",
    "\n",
    "################################## CLEAR FOLDERS #############################\n",
    "\n",
    "# Clear All Folders\n",
    "\n",
    "\n",
    "def ClearFolders():\n",
    "    fileList = glob.glob(r'2_Emotions\\*\\*.png')\n",
    "    for filePath in fileList:\n",
    "        try:\n",
    "            os.remove(filePath)\n",
    "        except:\n",
    "            print(\"Error while deleting file : \", filePath)\n",
    "\n",
    "\n",
    "    folder_path = (r'2b_Not_Face')\n",
    "    test = os.listdir(folder_path)\n",
    "    for images in test:\n",
    "        if images.endswith(\".png\"):\n",
    "            os.remove(os.path.join(folder_path, images))\n",
    "\n",
    "\n",
    "    folder_path = (r'2a_Face')\n",
    "    test = os.listdir(folder_path)\n",
    "    for images in test:\n",
    "        if images.endswith(\".png\"):\n",
    "            os.remove(os.path.join(folder_path, images))\n",
    "\n",
    "\n",
    "    folder_path = (r'1a_Blur_Images')\n",
    "    test = os.listdir(folder_path)\n",
    "    for images in test:\n",
    "        if images.endswith(\".png\"):\n",
    "            os.remove(os.path.join(folder_path, images))\n",
    "\n",
    "\n",
    "    folder_path = (r'1b_No_Blur')\n",
    "    test = os.listdir(folder_path)\n",
    "    for images in test:\n",
    "        if images.endswith(\".png\"):\n",
    "            os.remove(os.path.join(folder_path, images))\n",
    "\n",
    "\n",
    "    fileList1 = glob.glob(r'3a_Classifications\\*\\*.png')\n",
    "    for filePath in fileList1:\n",
    "        try:\n",
    "            os.remove(filePath)\n",
    "        except:\n",
    "            print(\"Error while deleting file : \", filePath)\n",
    "\n",
    "\n",
    "            \n",
    "################################## SYSTEM INTEGRATION #############################\n",
    "            \n",
    "# System Integration\n",
    "import PySimpleGUI as sg\n",
    "\n",
    "# Add your new theme colors and settings\n",
    "my_new_theme = {'BACKGROUND': '#3bbdc2',\n",
    "                'TEXT': 'white',\n",
    "                'INPUT': 'white',\n",
    "                'TEXT_INPUT': '#3D3D3D',\n",
    "                'SCROLL': '#c7e78b',\n",
    "                'BUTTON': ('white', '#FE5BAC'), #007489\n",
    "                'PROGRESS': ('#01826B', '#D0D0D0'),\n",
    "                'BORDER': 1,\n",
    "                'SLIDER_DEPTH': 0,\n",
    "                'PROGRESS_DEPTH': 0}\n",
    "\n",
    "# Add your dictionary to the PySimpleGUI themes\n",
    "sg.theme_add_new('MyNewTheme', my_new_theme)\n",
    "\n",
    "# Switch your theme to use the newly added one. You can add spaces to make it more readable\n",
    "sg.theme('My New Theme')\n",
    "\n",
    "def btn(name):  # a PySimpleGUI \"User Defined Element\" (see docs)\n",
    "    return sg.Button(name, size=(18, 2), font=(\"Helvetica\", 11), pad=(2, 2))\n",
    "\n",
    "# Define the window's contents\n",
    "layout = [[sg.Image(r'ai_logo.png')],\n",
    "          [sg.Text(\"\")],\n",
    "          [sg.Text(\"What's your name?\", size=(40, 1), font=(\"Helvetica\", 14))],\n",
    "          [sg.Input(key='-INPUT-', size=(60, 1))],\n",
    "          [sg.Text(\"\")],\n",
    "          [sg.Text(\"Blur Detection\", size=(40, 1), font=(\"Helvetica\", 14))],\n",
    "          [sg.Input(default_text='Input Local Folder Path', key='-PATH_Blur-', size=(60, 1))],\n",
    "          [sg.Text(\"\")],\n",
    "          [sg.Text(\"Face and Emotion\", size=(40, 1), font=(\"Helvetica\", 14))],\n",
    "          [sg.Input(default_text='Input Local Folder Path', key='-PATH_FaceEmotion-', size=(60, 1))],\n",
    "          [sg.Text(\"\")],\n",
    "          [sg.Text(\"Classify Favourites\", size=(40, 1), font=(\"Helvetica\", 14))],\n",
    "          [sg.Input(default_text='Input Local Folder Path', key='-PATH_Classify-', size=(60, 1))],\n",
    "          [sg.Text(size=(100,1), key='-OUTPUT-')],\n",
    "          [sg.Text(size=(100,1), key='-OUTPUTPATHBlur-')],\n",
    "          [sg.Text(size=(100,1), key='-OUTPUTPATHFaceAndEmotion-')],\n",
    "          [sg.Text(size=(100,1), key='-OUTPUTPATHClassification-')],\n",
    "          [sg.Text(size=(100,1), key='-OUTPUTPATHClearFolders-')],\n",
    "          [btn('Blur'), btn('Face and Emotion'), btn('Classify Favourites'), btn('Clear Albums'), btn('Quit')]]\n",
    "\n",
    "# Create the window\n",
    "window = sg.Window('ai@foto', layout)\n",
    "\n",
    "    \n",
    "# Display and interact with the Window using an Event Loop\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "    \n",
    "    if event == 'Blur' :\n",
    "        BlurDetection(values['-PATH_Blur-'])\n",
    "        #blur_detection(values['-PATH-'])\n",
    "        \n",
    "    if event == 'Face and Emotion' :\n",
    "        FaceAndEmotion(values['-PATH_FaceEmotion-'])\n",
    "        #blur_detection(values['-PATH-'])\n",
    "        \n",
    "    if event == 'Classify Favourites' :\n",
    "        Classification(values['-PATH_Classify-'])\n",
    "        #blur_detection(values['-PATH-'])\n",
    "        \n",
    "    if event == 'Clear Albums' :\n",
    "        ClearFolders()\n",
    "        #blur_detection(values['-PATH-'])\n",
    "    \n",
    "    # See if user wants to quit or window was closed\n",
    "    if event == sg.WINDOW_CLOSED or event == 'Quit':\n",
    "        break\n",
    "        \n",
    "    # Output a message to the window\n",
    "    window['-OUTPUT-'].update('Hello ' + values['-INPUT-'] + \"! Thanks for using our App\")\n",
    "    window['-OUTPUTPATHBlur-'].update('Your Path is for Blur Detection is :' + values['-PATH_Blur-'])\n",
    "    window['-OUTPUTPATHFaceAndEmotion-'].update('Your Path is for Face And Emotion is :' + values['-PATH_FaceEmotion-'])\n",
    "    window['-OUTPUTPATHClassification-'].update('Your Path is for Classify Favourites is :' + values['-PATH_Classify-'])\n",
    "    #window['-OUTPUTPATHClearFolders-'].update('Your albums are cleared' + values['-PATH_Clear-'])\n",
    "    \n",
    "# Finish up by removing from the screen\n",
    "window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mtcnn\n",
    "\n",
    "\n",
    "# import the necessary packages\n",
    "from pyimagesearch.blur_detector import detect_blur_fft\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import mtcnn\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import PySimpleGUI as sg\n",
    "import os\n",
    "\n",
    "fileList = glob.glob(r'2_Emotions\\*\\*.png')\n",
    "for filePath in fileList:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except:\n",
    "        print(\"Error while deleting file : \", filePath)\n",
    "\n",
    "\n",
    "folder_path = (r'2b_Not_Face')\n",
    "test = os.listdir(folder_path)\n",
    "for images in test:\n",
    "    if images.endswith(\".png\"):\n",
    "        os.remove(os.path.join(folder_path, images))\n",
    "\n",
    "\n",
    "folder_path = (r'2a_Face')\n",
    "test = os.listdir(folder_path)\n",
    "for images in test:\n",
    "    if images.endswith(\".png\"):\n",
    "        os.remove(os.path.join(folder_path, images))\n",
    "\n",
    "\n",
    "folder_path = (r'1a_Blur_Images')\n",
    "test = os.listdir(folder_path)\n",
    "for images in test:\n",
    "    if images.endswith(\".png\"):\n",
    "        os.remove(os.path.join(folder_path, images))\n",
    "\n",
    "\n",
    "folder_path = (r'1b_No_Blur')\n",
    "test = os.listdir(folder_path)\n",
    "for images in test:\n",
    "    if images.endswith(\".png\"):\n",
    "        os.remove(os.path.join(folder_path, images))\n",
    "\n",
    "\n",
    "fileList1 = glob.glob(r'3a_Classifications\\*\\*.png')\n",
    "for filePath in fileList1:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except:\n",
    "        print(\"Error while deleting file : \", filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
